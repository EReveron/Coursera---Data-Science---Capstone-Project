---
title: "Capstone Project - Final Report"
author: "Enrique Reveron"
date: "June 26, 2016"
output:
  html_document:
    fig_height: 4
    fig_width: 9
    keep_md: yes
    theme: default
  pdf_document: default
  word_document: default
---


```{r global_options, include=FALSE}
knitr::opts_chunk$set(echo=FALSE, warning=FALSE, message=TRUE)
```

## Executive Summary

This is a Milestone report related with the Coursera Capstone Project, the target is show initial exploratory data analysis about the US dataset that include three kind of files:

* Twitter
* News
* Blogs


## 1. Load the Neccesary Libraries

For this project we will use basicly the **quanteda**,**ggplot2**, **knitr** and **RColorBrewer**.

```{r echo=TRUE}
library(quanteda)
library(data.table)
library(ggplot2)
library(knitr)

#setwd("D:/Coursera/Capstone Project/Coursera-SwiftKey/final/en_US")
setwd("D:/001 -- Coursera/Capstone Project/Coursera-SwiftKey/final/en_US")

# For reproducibility
set.seed(12345)

```

## 2. Create Ngram Data Table

In order to create the Ngrams we will do several steps

### 2.1 Load All the Data

The files that we will use in the project are bigger than **150Mbytes** each one. In order to do the exploratory data analysis and to have an acceptable runtime, I will use only **10%** of the data. 

```{r createdata,echo=TRUE, cache = TRUE}
source("Create Ngrams Data Table vFinal.R")
create_mydata() 
```

### 2.2 Create All Tokens

```{r echo=TRUE, cache = TRUE}
create_alltokens()
```


### 2.3 Create Ngrams 

#### 2.3.1 Create and Clean Unigrams

```{r echo=TRUE, cache = TRUE}
create_ngram(n=1)
```


```{r echo=TRUE, cache = TRUE}
clean_ngram(n=1)
```



#### 2.3.2 Create and Clean Bigrams

```{r echo=TRUE, cache = TRUE}
create_ngram(n=2)
```



```{r echo=TRUE, cache = TRUE}
clean_ngram(n=2)
```


#### 2.3.3 Create and Clean Trigrams

```{r echo=TRUE, cache = TRUE}
create_ngram(n=3)
```


```{r echo=TRUE, cache = TRUE}
clean_ngram(n=2)
```


#### 2.3.4 Create and Clean Quadgrams

```{r echo=TRUE, cache = TRUE}
create_ngram(n=4)
```


```{r echo=TRUE, cache = TRUE}
clean_ngram(n=4)
```


### 2.4 Create and Trim DFM 

#### 2.4.1 Create and Trim Uni-dfm

```{r echo=TRUE, cache = TRUE}
create_dfm(n=1)
```


```{r echo=TRUE, cache = TRUE}
trim_dfm(n=1)
```


#### 2.4.2 Create and Trim Bi-dfm

```{r echo=TRUE, cache = TRUE}
create_dfm(n=2)
```


```{r echo=TRUE, cache = TRUE}
trim_dfm(n=2)
```


#### 2.4.3 Create and Trim Tri-dfm

```{r echo=TRUE, cache = TRUE}
create_dfm(n=3)
```


```{r echo=TRUE, cache = TRUE}
trim_dfm(n=3)
```

#### 2.4.4 Create and Trim Quad-dfm

```{r echo=TRUE, cache = TRUE}
create_dfm(n=4)
```


```{r echo=TRUE, cache = TRUE}
trim_dfm(n=4)
```


### 2.5 Create Data Table with Tokens and Frequency

#### 2.5.1 Create Unigram Data Table with Tokens and Frequency

```{r echo=TRUE, cache = TRUE}
create_DT(n=1)
```


#### 2.5.2 Create Bigram Data Table with Tokens and Frequency

```{r echo=TRUE, cache = TRUE}
create_DT(n=2)
```

#### 2.5.3 Create Trigram Data Table with Tokens and Frequency

```{r echo=TRUE, cache = TRUE}
create_DT(n=3)
```

#### 2.5.4 Create Quadgram Data Table with Tokens and Frequency

```{r echo=TRUE, cache = TRUE}
create_DT(n=4)
```

### 3. Calculate Probability for Each Ngram

### 3.1 Create Unigram Knersey-ney Probability Table

The files that we will use in the project are bigger than **150Mbytes** each one. In order to


```{r echo=TRUE}
source("Knersey-ney vFinal.R")

init_DT_tables() 
calculate_prob_kn(1)
```


Those are information in the Unigram DT:

```{r echo=TRUE, results='asis'}
# Print the basic information about the files. 
#kable(DT.uni[1:10])
```

The prob table has:

```{r echo=TRUE, results='asis'}
# Print the basic information about the files. 
#kable(DT.uni.prob[1:10])
```

### 3.2 Create Bigram Knersey-ney Probability Table

The files that we will use in the project are bigger than **150Mbytes** each one. In order to


```{r echo=TRUE, cache = TRUE}
init_DT_tables() 
calculate_prob_kn(2)
```

Those are information in the Unigram DT:

```{r echo=TRUE, results='asis'}
# Print the basic information about the files. 
#kable(DT.bi[1:10])
```

The prob table has:

```{r echo=TRUE, results='asis'}
# Print the basic information about the files. 
#kable(DT.bi.prob[1:10])
```


### 3.3 Create Trigram Knersey-ney Probability Table

The files that we will use in the project are bigger than **150Mbytes** each one. In order to


```{r echo=TRUE, cache = TRUE}
calculate_prob_kn(3)
```

Those are information in the Unigram DT:

```{r echo=TRUE, results='asis'}
# Print the basic information about the files. 
#kable(DT.tri[1:10])
```

The prob table has:

```{r echo=TRUE, results='asis'}
# Print the basic information about the files. 
#kable(DT.tri.prob[1:10])
```

### 3.4 Create Quadgram Knersey-ney Probability Table

The files that we will use in the project are bigger than **150Mbytes** each one. In order to


```{r echo=TRUE, cache = TRUE}
calculate_prob_kn(4)
```

Those are information in the Unigram DT:

```{r echo=TRUE, results='asis'}
# Print the basic information about the files. 
#kable(DT.quad[1:10])
```

The prob table has:

```{r echo=TRUE, results='asis'}
# Print the basic information about the files. 
#kable(DT.quad.prob[1:10])
```


## 4. Prediction of next word

### 4.1 Example with Unigram

```{r echo=TRUE} 
#source("Pred Next Word vFinal.R")
#prediction1 <- predict_nextword(c("how"),100,0,5) 
```

```{r echo=TRUE, results='asis'} 
# Print the basic information about the files.  
#kable(prediction1)
```

### 4.2 Example with Bigram

```{r echo=TRUE} 
#prediction2 <- predict_nextword(c("how","are"),100,0,5) 
```

```{r echo=TRUE, results='asis'} 
# Print the basic information about the files.  
#kable(prediction2)
```

### 4.3 Example with Trigram

```{r echo=TRUE} 
#prediction3 <- predict_nextword(c("how","are","you"),100,0,5) 
```

```{r echo=TRUE, results='asis'}
# Print the basic information about the files. 
#kable(prediction3)
```


## 4. Prediction of next word using Regex

```{r echo=TRUE} 
#source("Pred Next Word vFinal.R")
#source("Pred Next Word Regex vFinal.R")
#prediction1 <- predict_nextword_regex(c("how","are",""),100,0,5)
#prediction2 <- predict_nextword(c("how","are"),100,0,5)
```


```{r echo=TRUE, results='asis'}
# Print the basic information about the files. 
#kable(prediction1)
#kable(prediction2)
```
